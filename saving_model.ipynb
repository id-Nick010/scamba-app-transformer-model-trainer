{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0035fa2b-08e0-4bda-b8d1-900f7bd636d9",
   "metadata": {},
   "source": [
    "# Model Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b0221-74cb-4d35-8dd9-b8d26a680f96",
   "metadata": {},
   "source": [
    "### Model Name Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85442eb1-bd56-40f7-89db-3bba711906d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "saved_model_name = \"xlm-r_88acc_best_model_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "444e62b6-2953-4d1e-9878-d4437815098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "saved_model_name = \"mbert_80pacc_try_model_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d76d374-e82a-4950-9538-a29db442ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-uncased'\n",
    "saved_model_name = \"bert-base_best_model_v1\"\n",
    "load_checkpoint_name = \"bert-base__lr3e-05_ep100_bs64.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b453d2e-66b8-43e8-bf5c-de0762d02456",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b930b8fb-715b-4c94-8976-5d1562d0001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "model.load_weights('checkpoints/' + load_checkpoint_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617334e2-9963-41bd-ba25-380418749391",
   "metadata": {},
   "source": [
    "### Save Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5da32e-1f1f-49f7-abd5-3d59abe685c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Transformer Format\n",
    "model.save_pretrained(\"saved_model/\"+saved_model_name, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b22e5-51f8-4e10-9a39-d948c4c61e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keras Format\n",
    "model.save(\"saved_model/\"+saved_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c57e2538-88bb-4a35-9853-5d2eb94c3ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/bert-base_best_model_v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/bert-base_best_model_v1/assets\n"
     ]
    }
   ],
   "source": [
    "# Standard Tensorflow Format\n",
    "import tensorflow as tf\n",
    "tf.saved_model.save(model, \"saved_model/\"+saved_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5110134-6ce6-459a-a30f-1c6fbe979fc5",
   "metadata": {},
   "source": [
    "# Tokenizer Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66bdb18-33bc-43e3-a268-3d4b57004aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"xlm-roberta-base\"\n",
    "tokenizer_saved_name = \"for_\" + \"xmlr-pd-best_fix_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3df2424-1ccc-4b64-8d33-9d18fc3c4435",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer_saved_name = \"for_\" + \"mbert_80pacc_try_model_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77bca9eb-0806-4e64-9414-12409b858c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_tokenizer/for_mbert_80pacc_try_model_v1/tokenizer_config.json',\n",
       " 'saved_tokenizer/for_mbert_80pacc_try_model_v1/special_tokens_map.json',\n",
       " 'saved_tokenizer/for_mbert_80pacc_try_model_v1/vocab.txt',\n",
       " 'saved_tokenizer/for_mbert_80pacc_try_model_v1/added_tokens.json',\n",
       " 'saved_tokenizer/for_mbert_80pacc_try_model_v1/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Assume you already have a tokenizer (for instance, fine-tuned or pretrained)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "# Save the tokenizer to a local directory\n",
    "tokenizer.save_pretrained(\"saved_tokenizer/\" + tokenizer_saved_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54675b7-be56-4d0b-944a-904e62fda945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
